{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.091450500Z",
     "start_time": "2024-04-16T12:37:10.086868400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataset_tools as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.122758900Z",
     "start_time": "2024-04-16T12:37:12.091450500Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregated_dataset = pd.read_csv('datasets/per_day_participant_dataset_co_w_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.169469100Z",
     "start_time": "2024-04-16T12:37:12.122758900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0.1  Unnamed: 0       id        date  mood  mood_count  \\\n2149          2149        2149  AS14.33  2014-05-27   6.2           5   \n2150          2150        2150  AS14.33  2014-05-28   8.2           5   \n2151          2151        2151  AS14.33  2014-05-29   7.0           3   \n2152          2152        2152  AS14.33  2014-05-30   6.8           5   \n2153          2153        2153  AS14.33  2014-05-31   7.0           1   \n\n      circumplex.arousal  circumplex.arousal_count  circumplex.valence  \\\n2149           -0.600000                         5                 0.4   \n2150            0.000000                         5                 1.2   \n2151           -1.333333                         3                 1.0   \n2152           -0.800000                         5                -0.4   \n2153           -2.000000                         1                 1.0   \n\n      circumplex.valence_count  ...  appCat.social  appCat.social_count  \\\n2149                         5  ...       2010.364                   40   \n2150                         5  ...       5361.211                   54   \n2151                         3  ...       1789.922                    9   \n2152                         5  ...       3166.409                   42   \n2153                         1  ...          0.000                    0   \n\n      appCat.travel  appCat.travel_count  appCat.unknown  \\\n2149          0.000                    0           0.000   \n2150          0.000                    0           0.000   \n2151          0.939                    1           0.000   \n2152       1052.648                   28           8.072   \n2153          0.000                    0           0.000   \n\n      appCat.unknown_count  appCat.utilities  appCat.utilities_count  \\\n2149                     0            56.173                       3   \n2150                     0            30.666                       6   \n2151                     0             3.199                       2   \n2152                     3           232.825                      15   \n2153                     0             0.000                       0   \n\n      appCat.weather  appCat.weather_count  \n2149             0.0                     0  \n2150             0.0                     0  \n2151             0.0                     0  \n2152             0.0                     0  \n2153             0.0                     0  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>date</th>\n      <th>mood</th>\n      <th>mood_count</th>\n      <th>circumplex.arousal</th>\n      <th>circumplex.arousal_count</th>\n      <th>circumplex.valence</th>\n      <th>circumplex.valence_count</th>\n      <th>...</th>\n      <th>appCat.social</th>\n      <th>appCat.social_count</th>\n      <th>appCat.travel</th>\n      <th>appCat.travel_count</th>\n      <th>appCat.unknown</th>\n      <th>appCat.unknown_count</th>\n      <th>appCat.utilities</th>\n      <th>appCat.utilities_count</th>\n      <th>appCat.weather</th>\n      <th>appCat.weather_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2149</th>\n      <td>2149</td>\n      <td>2149</td>\n      <td>AS14.33</td>\n      <td>2014-05-27</td>\n      <td>6.2</td>\n      <td>5</td>\n      <td>-0.600000</td>\n      <td>5</td>\n      <td>0.4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>2010.364</td>\n      <td>40</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>56.173</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2150</th>\n      <td>2150</td>\n      <td>2150</td>\n      <td>AS14.33</td>\n      <td>2014-05-28</td>\n      <td>8.2</td>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>5</td>\n      <td>1.2</td>\n      <td>5</td>\n      <td>...</td>\n      <td>5361.211</td>\n      <td>54</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>30.666</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2151</th>\n      <td>2151</td>\n      <td>2151</td>\n      <td>AS14.33</td>\n      <td>2014-05-29</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>-1.333333</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1789.922</td>\n      <td>9</td>\n      <td>0.939</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>3.199</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2152</th>\n      <td>2152</td>\n      <td>2152</td>\n      <td>AS14.33</td>\n      <td>2014-05-30</td>\n      <td>6.8</td>\n      <td>5</td>\n      <td>-0.800000</td>\n      <td>5</td>\n      <td>-0.4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3166.409</td>\n      <td>42</td>\n      <td>1052.648</td>\n      <td>28</td>\n      <td>8.072</td>\n      <td>3</td>\n      <td>232.825</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2153</th>\n      <td>2153</td>\n      <td>2153</td>\n      <td>AS14.33</td>\n      <td>2014-05-31</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>-2.000000</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.185088700Z",
     "start_time": "2024-04-16T12:37:12.169469100Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOT NEEDED ANYMORE\n",
    "# Pares column Unnamed: 0\n",
    "# aggregated_dataset = dt.reformat_aggregated_data(aggregated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.247587100Z",
     "start_time": "2024-04-16T12:37:12.185088700Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOT NEEDED ANYMORE\n",
    "# average the first 3 columns using the counts\n",
    "# aggregated_dataset = dt.average_data(aggregated_dataset, dt.var_names[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.356965700Z",
     "start_time": "2024-04-16T12:37:12.200716200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0.1  Unnamed: 0       id        date  mood  mood_count  \\\n0             0           0  AS14.01  2014-02-17   0.0           0   \n1             1           1  AS14.01  2014-02-18   0.0           0   \n2             2           2  AS14.01  2014-02-19   0.0           0   \n3             3           3  AS14.01  2014-02-20   0.0           0   \n4             4           4  AS14.01  2014-02-21   0.0           0   \n\n   circumplex.arousal  circumplex.arousal_count  circumplex.valence  \\\n0                 0.0                         0                 0.0   \n1                 0.0                         0                 0.0   \n2                 0.0                         0                 0.0   \n3                 0.0                         0                 0.0   \n4                 0.0                         0                 0.0   \n\n   circumplex.valence_count  ...  appCat.social  appCat.social_count  \\\n0                         0  ...            0.0                    0   \n1                         0  ...            0.0                    0   \n2                         0  ...            0.0                    0   \n3                         0  ...            0.0                    0   \n4                         0  ...            0.0                    0   \n\n   appCat.travel  appCat.travel_count  appCat.unknown  appCat.unknown_count  \\\n0            0.0                    0             0.0                     0   \n1            0.0                    0             0.0                     0   \n2            0.0                    0             0.0                     0   \n3            0.0                    0             0.0                     0   \n4            0.0                    0             0.0                     0   \n\n   appCat.utilities  appCat.utilities_count  appCat.weather  \\\n0               0.0                       0             0.0   \n1               0.0                       0             0.0   \n2               0.0                       0             0.0   \n3               0.0                       0             0.0   \n4               0.0                       0             0.0   \n\n   appCat.weather_count  \n0                     0  \n1                     0  \n2                     0  \n3                     0  \n4                     0  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>date</th>\n      <th>mood</th>\n      <th>mood_count</th>\n      <th>circumplex.arousal</th>\n      <th>circumplex.arousal_count</th>\n      <th>circumplex.valence</th>\n      <th>circumplex.valence_count</th>\n      <th>...</th>\n      <th>appCat.social</th>\n      <th>appCat.social_count</th>\n      <th>appCat.travel</th>\n      <th>appCat.travel_count</th>\n      <th>appCat.unknown</th>\n      <th>appCat.unknown_count</th>\n      <th>appCat.utilities</th>\n      <th>appCat.utilities_count</th>\n      <th>appCat.weather</th>\n      <th>appCat.weather_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>AS14.01</td>\n      <td>2014-02-17</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>AS14.01</td>\n      <td>2014-02-18</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>AS14.01</td>\n      <td>2014-02-19</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>AS14.01</td>\n      <td>2014-02-20</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>AS14.01</td>\n      <td>2014-02-21</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.497593200Z",
     "start_time": "2024-04-16T12:37:12.247587100Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "aggregated_dataset.to_csv('datasets/aggregated_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.544484900Z",
     "start_time": "2024-04-16T12:37:12.341343100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where mood_count is 0: 886 out of 2154\n"
     ]
    }
   ],
   "source": [
    "# count the number of rows where mood_count is 0\n",
    "zero_mood_count = aggregated_dataset[aggregated_dataset['mood_count'] == 0].shape[0]\n",
    "print('Number of rows where mood_count is 0:', zero_mood_count, 'out of', aggregated_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:12.575715100Z",
     "start_time": "2024-04-16T12:37:12.372588900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "id\nAS14.01    31\nAS14.02    27\nAS14.03    34\nAS14.05    24\nAS14.06    36\nAS14.07     2\nAS14.08    16\nAS14.09    32\nAS14.12    35\nAS14.13    24\nAS14.14    34\nAS14.15    26\nAS14.16    25\nAS14.17    22\nAS14.19    32\nAS14.20    31\nAS14.23    38\nAS14.24     7\nAS14.25    51\nAS14.26    35\nAS14.27    46\nAS14.28    43\nAS14.29    46\nAS14.30    31\nAS14.31    47\nAS14.32    50\nAS14.33    61\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_of_empty_mood = aggregated_dataset[aggregated_dataset['mood_count'] == 0].groupby('id').size()\n",
    "counts_of_empty_mood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:13.794228100Z",
     "start_time": "2024-04-16T12:37:12.403839100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'AS14.01': {9: 1, 21: 1, 1: 1},\n 'AS14.02': {27: 1},\n 'AS14.03': {32: 1, 1: 1},\n 'AS14.05': {24: 1},\n 'AS14.06': {35: 1, 1: 1},\n 'AS14.07': {2: 1},\n 'AS14.08': {16: 1},\n 'AS14.09': {32: 1},\n 'AS14.12': {24: 1, 11: 1},\n 'AS14.13': {24: 1},\n 'AS14.14': {31: 1, 1: 1, 2: 1},\n 'AS14.15': {25: 1, 1: 1},\n 'AS14.16': {24: 1, 1: 1},\n 'AS14.17': {15: 1, 6: 1, 1: 1},\n 'AS14.19': {32: 1},\n 'AS14.20': {31: 1},\n 'AS14.23': {33: 1, 1: 1},\n 'AS14.24': {5: 1, 1: 1},\n 'AS14.25': {50: 1, 1: 1},\n 'AS14.26': {34: 1, 1: 1},\n 'AS14.27': {45: 1, 1: 1},\n 'AS14.28': {42: 1, 1: 1},\n 'AS14.29': {44: 1, 1: 2},\n 'AS14.30': {31: 1},\n 'AS14.31': {44: 1, 1: 1},\n 'AS14.32': {43: 1, 2: 1, 1: 3},\n 'AS14.33': {58: 1, 2: 1, 1: 1}}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants = aggregated_dataset['id'].unique()\n",
    "current_participant = participants[0]\n",
    "# count lenght of empty mood sequences\n",
    "empty_mood_sequences = {}\n",
    "\"\"\"\n",
    "Dictionry with the form of:\n",
    "{\n",
    "    'id': {\n",
    "        'length_sequence': count\n",
    "    }\n",
    "}\n",
    "\n",
    "Example:\n",
    "\n",
    "{\n",
    "    'AS14.01': {\n",
    "        1: 10,\n",
    "        2: 5\n",
    "    },\n",
    "    'AS14.02': {\n",
    "        1: 7,\n",
    "        2: 3\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for participant in participants:\n",
    "    current_length = 0\n",
    "    for index, row in aggregated_dataset[aggregated_dataset['id'] == participant].iterrows():\n",
    "        if row['mood_count'] == 0:\n",
    "            current_length += 1\n",
    "            if index == len(aggregated_dataset[aggregated_dataset['id'] == participant]) - 1:\n",
    "                \n",
    "                if participant not in empty_mood_sequences:\n",
    "                    empty_mood_sequences[participant] = {}\n",
    "                if current_length not in empty_mood_sequences[participant]:\n",
    "                    empty_mood_sequences[participant][current_length] = 0\n",
    "                empty_mood_sequences[participant][current_length] += 1\n",
    "\n",
    "                current_length = 0\n",
    "        else:\n",
    "            if current_length != 0:\n",
    "                if participant not in empty_mood_sequences:\n",
    "                    empty_mood_sequences[participant] = {}\n",
    "                if current_length not in empty_mood_sequences[participant]:\n",
    "                    empty_mood_sequences[participant][current_length] = 0\n",
    "                empty_mood_sequences[participant][current_length] += 1\n",
    "            current_length = 0\n",
    "\n",
    "empty_mood_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:26.278484500Z",
     "start_time": "2024-04-16T12:37:13.794228100Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot mood_count per participant\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "if not os.path.exists('participant_mood_count'):\n",
    "    os.makedirs('participant_mood_count')\n",
    "\n",
    "for participant in participants:\n",
    "    plt.plot(aggregated_dataset[aggregated_dataset['id'] == participant]['date'], aggregated_dataset[aggregated_dataset['id'] == participant]['mood_count'])\n",
    "    plt.title('Participant ' + participant + ' mood count')\n",
    "    plt.savefig('participant_mood_count/' + participant + '_mood_count.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:31.806510800Z",
     "start_time": "2024-04-16T12:37:26.278484500Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# plot per participant the sum of the variables that end with _count\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m participant \u001B[38;5;129;01min\u001B[39;00m participants:\n\u001B[1;32m----> 3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(aggregated_dataset[aggregated_dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m participant][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[43maggregated_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43maggregated_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mparticipant\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParticipant \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m participant \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m sum of the variables that end with _count\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\generic.py:11512\u001B[0m, in \u001B[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001B[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m  11493\u001B[0m \u001B[38;5;129m@doc\u001B[39m(  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m  11494\u001B[0m     _num_doc,\n\u001B[0;32m  11495\u001B[0m     desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturn the sum of the values over the requested axis.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  11510\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  11511\u001B[0m ):\n\u001B[1;32m> 11512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNDFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\generic.py:11280\u001B[0m, in \u001B[0;36mNDFrame.sum\u001B[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m  11272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msum\u001B[39m(\n\u001B[0;32m  11273\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  11274\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  11278\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  11279\u001B[0m ):\n\u001B[1;32m> 11280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_min_count_stat_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  11281\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnanops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnansum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m  11282\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\generic.py:11263\u001B[0m, in \u001B[0;36mNDFrame._min_count_stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m  11260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m  11261\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_axis_number\n\u001B[1;32m> 11263\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  11264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11266\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  11270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\frame.py:10519\u001B[0m, in \u001B[0;36mDataFrame._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m  10515\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m  10517\u001B[0m \u001B[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001B[39;00m\n\u001B[0;32m  10518\u001B[0m \u001B[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001B[39;00m\n\u001B[1;32m> 10519\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblk_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m  10520\u001B[0m out \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39m_constructor(res)\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m  10521\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001B[0m, in \u001B[0;36mBlockManager.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m   1532\u001B[0m res_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1533\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m-> 1534\u001B[0m     nbs \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1535\u001B[0m     res_blocks\u001B[38;5;241m.\u001B[39mextend(nbs)\n\u001B[0;32m   1537\u001B[0m index \u001B[38;5;241m=\u001B[39m Index([\u001B[38;5;28;01mNone\u001B[39;00m])  \u001B[38;5;66;03m# placeholder\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001B[0m, in \u001B[0;36mBlock.reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001B[39;00m\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001B[39;00m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m--> 339\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    342\u001B[0m         \u001B[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001B[39;00m\n\u001B[0;32m    343\u001B[0m         res_values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([[result]])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\frame.py:10482\u001B[0m, in \u001B[0;36mDataFrame._reduce.<locals>.blk_func\u001B[1;34m(values, axis)\u001B[0m\n\u001B[0;32m  10480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\u001B[38;5;241m.\u001B[39m_reduce(name, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m  10481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m> 10482\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\nanops.py:96\u001B[0m, in \u001B[0;36mdisallow.__call__.<locals>._f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(invalid\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 96\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;66;03m# we want to transform an object array\u001B[39;00m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;66;03m# ValueError message to the more typical TypeError\u001B[39;00m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# e.g. this is normally a disallowed function on\u001B[39;00m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;66;03m# object arrays that contain strings\u001B[39;00m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(args[\u001B[38;5;241m0\u001B[39m]):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\nanops.py:421\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    419\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 421\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[0;32m    424\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\nanops.py:494\u001B[0m, in \u001B[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001B[1;34m(values, axis, **kwargs)\u001B[0m\n\u001B[0;32m    491\u001B[0m         results \u001B[38;5;241m=\u001B[39m [func(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrs]\n\u001B[0;32m    492\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(results)\n\u001B[1;32m--> 494\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\pandas\\core\\nanops.py:652\u001B[0m, in \u001B[0;36mnansum\u001B[1;34m(values, axis, skipna, min_count, mask)\u001B[0m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_timedelta64_dtype(dtype):\n\u001B[0;32m    650\u001B[0m     dtype_sum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m--> 652\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m \u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_sum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    653\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m _maybe_null_out(the_sum, axis, mask, values\u001B[38;5;241m.\u001B[39mshape, min_count\u001B[38;5;241m=\u001B[39mmin_count)\n\u001B[0;32m    655\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m the_sum\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml24\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001B[0m, in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     48\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# plot per participant the sum of the variables that end with _count\n",
    "for participant in participants:\n",
    "    plt.plot(aggregated_dataset[aggregated_dataset['id'] == participant]['date'], aggregated_dataset[aggregated_dataset['id'] == participant].iloc[:, 3::2].sum(axis=1))\n",
    "    plt.title('Participant ' + participant + ' sum of the variables that end with _count')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:31.824979400Z",
     "start_time": "2024-04-16T12:37:31.806510800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot both\n",
    "def plot_counts_per_participant(df):\n",
    "    participants = df['id'].unique()\n",
    "    for participant in participants:\n",
    "        plt.plot(df[df['id'] == participant]['date'], df[df['id'] == participant]['mood_count'])\n",
    "        plt.title('Participant ' + participant + ' mood count')\n",
    "        plt.show()\n",
    "        plt.plot(df[df['id'] == participant]['date'], df[df['id'] == participant].iloc[:, 3::2].sum(axis=1))\n",
    "        plt.title('Participant ' + participant + ' sum of the _count variables')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_counts_per_participant(aggregated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.824118200Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "aggregated_dataset = pd.read_csv('datasets/aggregated_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.824979400Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregated_dataset['sum_of_counts'] = aggregated_dataset.iloc[:, 3::2].sum(axis=1)\n",
    "aggregated_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T12:37:31.888268600Z",
     "start_time": "2024-04-16T12:37:31.824979400Z"
    }
   },
   "outputs": [],
   "source": [
    "# strip the first rows and the last rows with mood_count = 0 per participant\n",
    "aggregated_dataset_cleaned = pd.DataFrame()\n",
    "for participant in participants:\n",
    "    participant_data = aggregated_dataset[aggregated_dataset['id'] == participant]\n",
    "    participant_data.reset_index(drop=True, inplace=True)\n",
    "    first_non_zero_mood = participant_data[participant_data['mood_count'] != 0].index[0]\n",
    "    last_non_zero_mood = participant_data[participant_data['mood_count'] != 0].index[-1]\n",
    "    aggregated_dataset_cleaned = pd.concat([aggregated_dataset_cleaned, participant_data[first_non_zero_mood:last_non_zero_mood+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.841099100Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape:', aggregated_dataset.shape)\n",
    "print('Cleaned dataset shape:', aggregated_dataset_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.841099100Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove the period of 10 or more consecutive lower sum of the variables that end with _count per participant, splitting the dataset in batches. The treshold depends on the mean of the sum of the variables that end with _count\n",
    "aggregated_dataset_cleaned = aggregated_dataset.copy(deep=True)\n",
    "\n",
    "aggregated_dataset_cleaned.reset_index(drop=True, inplace=True)\n",
    "aggregated_dataset_cleaned.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.857320400Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing math\n",
    "import math\n",
    "\n",
    "\n",
    "def split_dataset(df, max_empty_lenght=4, min_count=10):\n",
    "    participants = df['id'].unique()\n",
    "    splitted_dataset = pd.DataFrame()\n",
    "    for participant in participants:\n",
    "        participant_data = df[df['id'] == participant]\n",
    "        participant_data.reset_index(drop=True, inplace=True)\n",
    "        mean_sum_of_counts = participant_data['sum_of_counts'].mean()\n",
    "        #std_sum_of_counts = participant_data['sum_of_counts'].std()\n",
    "        treshold = max(mean_sum_of_counts - 3*math.sqrt(mean_sum_of_counts), min_count) # 99% confidence interval assuming poisson distribution approximated by normal distribution\n",
    "        print('threshold for participant', participant, 'is', treshold)\n",
    "        current_length = 0\n",
    "        batch_number = 0\n",
    "        previous_cut = 0\n",
    "        for index, row in participant_data.iterrows():\n",
    "            if row['sum_of_counts'] <= treshold:\n",
    "                current_length += 1\n",
    "\n",
    "            elif current_length > max_empty_lenght:\n",
    "                batch = participant_data[previous_cut:index-current_length+(max_empty_lenght if previous_cut else 0)].copy(deep=True)\n",
    "                batch['batch'] = batch_number\n",
    "                splitted_dataset = pd.concat([splitted_dataset, batch])\n",
    "\n",
    "                batch_number += 1 if previous_cut else 0\n",
    "                current_length = 0\n",
    "                previous_cut = index\n",
    "            else:\n",
    "                current_length = 0\n",
    "            if index == len(participant_data) - 1:\n",
    "                if current_length <= max_empty_lenght:\n",
    "                    batch = participant_data[previous_cut:].copy(deep=True)\n",
    "                    batch['batch'] = batch_number\n",
    "                    splitted_dataset = pd.concat([splitted_dataset, batch])\n",
    "    return splitted_dataset\n",
    "\n",
    "splitted_dataset = split_dataset(aggregated_dataset_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.857320400Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataset shape:', aggregated_dataset_cleaned.shape)\n",
    "print('Splitted dataset shape:', splitted_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.857320400Z"
    }
   },
   "outputs": [],
   "source": [
    "# print lenght per batch\n",
    "splitted_dataset.groupby(['id', 'batch']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.857320400Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot counts\n",
    "splitted_dataset['date'] = pd.to_datetime(splitted_dataset['date'])\n",
    "dt.plot_counts_per_participant(splitted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.873811600Z"
    }
   },
   "outputs": [],
   "source": [
    "reordered_columns = splitted_dataset.columns.to_list()[0:2]+splitted_dataset.columns.to_list()[-1:] + splitted_dataset.columns.to_list()[2:-1]\n",
    "splitted_dataset = splitted_dataset[reordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.873811600Z"
    }
   },
   "outputs": [],
   "source": [
    "splitted_dataset[splitted_dataset['id'] == 'AS14.01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-16T12:37:31.873811600Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "splitted_dataset.to_csv('datasets/splitted_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
